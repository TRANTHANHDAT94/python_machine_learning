{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization\n",
    "![](https://doc.plob.org/machine_learning/07_Regularization_files/Image.png)\n",
    "![](https://www.globalsoftwaresupport.com/wp-content/uploads/2018/02/lkklk888.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We alway have:\n",
    "- Bias: sai số mô hình nặng --> build model very clear to descrese the erorr\n",
    "- Overfit: Không mang tính tổng quan và chỉ cho modeldatabase when using as real -> failure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "38ed2648d44595868ec2fc83517bb6e42998b133"
   },
   "source": [
    "**Table of Content:** <br/>\n",
    "This notebook is an illustration of how **regularized linear models** work, using the house prices **training** set. <br/>\n",
    "\n",
    "* Single-variable models (for illustration purposes)\n",
    "    * Ridge regression\n",
    "    * Lasso regression\n",
    "    * Elastic net\n",
    "* Multi-variable models\n",
    "    * Elastic net\n",
    "    * SGD and early stopping (with k-fold splitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'input/Lecture_04_3/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4b81408a1687>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"input/Lecture_04_3/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'input/Lecture_04_3/'"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(os.listdir(\"input/Lecture_04_3/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "57541b1f0d3504aa4a73218f328b761017fa8eb8"
   },
   "outputs": [],
   "source": [
    "plt.rc('axes', lw = 1.5)\n",
    "plt.rc('xtick', labelsize = 14)\n",
    "plt.rc('ytick', labelsize = 14)\n",
    "plt.rc('xtick.major', size = 5, width = 3)\n",
    "plt.rc('ytick.major', size = 5, width = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "source": [
    "We will first choose just one independent variable for visualization purpose, and try out different regularized linear models. Later we will expand the models to multiple independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "be67b4481e345870f469d7eda8e8dadc79c631b9"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'input/Lecture_04_3/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-09adf6ad7c39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# open the training dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataTrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input/Lecture_04_3/train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdataTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/anthony/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/anthony/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/anthony/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/anthony/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/anthony/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/anthony/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1368\u001b[0;31m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m         )\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/anthony/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    650\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m             )\n\u001b[1;32m    654\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'input/Lecture_04_3/train.csv'"
     ]
    }
   ],
   "source": [
    "# open the training dataset\n",
    "dataTrain = pd.read_csv('input/Lecture_04_3/train.csv')\n",
    "dataTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "d37b351b3795bdc442f7ef5c3812c87e8fc2b610"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataTrain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7e9fd60163ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#We will focus only on numeric features here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnumerics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'int16'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'int32'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'int64'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'float16'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'float32'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'float64'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdataTrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumerics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdataTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataTrain' is not defined"
     ]
    }
   ],
   "source": [
    "#We will focus only on numeric features here. \n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "dataTrain = dataTrain.select_dtypes(include=numerics)\n",
    "dataTrain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "52aef20e91d4eae12f749225296f76efec918032"
   },
   "source": [
    "# Single Variable Models (for illustration purposes)\n",
    "**We simplify the data for the purpose of illustration and introduction of the regularized models. **  \n",
    "Later we will include multiple variables in the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a956bfb8c18fdaaa69375e32988f4ae45a72b76f"
   },
   "outputs": [],
   "source": [
    "dataTrain = dataTrain[['GarageArea','SalePrice']]\n",
    "dataTrain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b5b15a078997623f8a9d5475301cb7b1cc54f3d3"
   },
   "source": [
    "Check to see if there are any missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "b5ced5a6ca5f518ff9e7a1ff9f5bd2c6132b5c83"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataTrain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fd7ae0607ef6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dataTrain' is not defined"
     ]
    }
   ],
   "source": [
    "dataTrain.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d1749349aefb8e3eff18421e4293e19e77231132"
   },
   "source": [
    "No missing values, so we don't have to worry much about data cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2902397b8e9717ed0673d8a50595ca47a1d4af80"
   },
   "outputs": [],
   "source": [
    "# Take a look at the data. \n",
    "plt.plot('GarageArea','SalePrice',data=dataTrain, marker = 'o', linestyle = '')\n",
    "plt.ylabel('Sale Price (dollars)', fontsize = 18)\n",
    "plt.xlabel('Garage Area (square feet)', fontsize = 18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "489b5a023bc08b2374ac0be9df486bb4fab42d80"
   },
   "outputs": [],
   "source": [
    "# format training data\n",
    "xTrain = dataTrain['GarageArea'].values.reshape(-1,1) # as_matrix is deprecated since version 0.23.0\n",
    "yTrain = dataTrain['SalePrice'].values.reshape(-1,1)\n",
    "xTrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "029e532abcbeb4752abcccf75a8d1a9a74c9297a"
   },
   "source": [
    "Let's first do a degree 10 linear regression model **without** regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a7208be77e907175942ed289555090c120b3d03d"
   },
   "outputs": [],
   "source": [
    "# Transform the input features\n",
    "Poly = PolynomialFeatures(degree = 10, include_bias = False)\n",
    "xTrainPoly = Poly.fit_transform(xTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6bc2b105ec1c7c2ab51be4a7ce050aea41649ab4"
   },
   "source": [
    "we standardize input features through **Scikit-learn**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "381dad171bb758d118f7c730af117499adabcc00"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# standardization\n",
    "scaler = StandardScaler()\n",
    "xTrainPolyStan = scaler.fit_transform(xTrainPoly)\n",
    "scaler.scale_, scaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "af36a6b62864b607c0d4076a3b3375bbc9b99aba"
   },
   "outputs": [],
   "source": [
    "# linear regression\n",
    "reg = LinearRegression()\n",
    "reg.fit(xTrainPolyStan, yTrain)\n",
    "\n",
    "# predict\n",
    "xFit = np.linspace(0,1500,num=200).reshape(-1,1)\n",
    "xFitPoly = Poly.transform(xFit)\n",
    "xFitPolyStan = scaler.transform(xFitPoly)\n",
    "yFit = reg.predict(xFitPolyStan)\n",
    "\n",
    "# plot\n",
    "plt.plot(xFit,yFit, lw=3, color='r', zorder = 2)\n",
    "plt.plot('GarageArea','SalePrice',data=dataTrain, marker = 'o', color = 'b', linestyle = '', zorder = 1)\n",
    "plt.ylabel('Sale Price (dollars)', fontsize = 18)\n",
    "plt.xlabel('Garage Area (square feet)', fontsize = 18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Regularization Term\n",
    "![](https://laid.delanover.com/wp-content/uploads/2018/01/reg_formulas.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.researchgate.net/profile/Frank_Emmert-Streib/publication/330380054/figure/tbl2/AS:715185664823298@1547524958338/Overview-of-regularization-or-penalty-terms-and-methods-utilizing-them.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6e3faa7cf81eaa12ade117f3689513f4d5afe2f3"
   },
   "source": [
    "## Ridge Regression\n",
    "Regular linear regression has the form of: <br>$J(\\theta) = MSE(\\theta)$ </br>\n",
    "\n",
    "Ridge regression appy a regularization term proportional to the **square of L2-norm** of feature weights (not including the intercept). A common expression is: \n",
    "<br>\n",
    "$J(\\theta) = MSE(\\theta) + \\frac{\\alpha}{2} (\\theta_1^2 + \\theta_2^2 + ... + \\theta_n^2)$\n",
    "</br>\n",
    "\n",
    "The corrsponding expression for gradient of theta and the optimal solution for theta will change, due to the additonal term. We can also use the **Scikit-Learn** package to do ridge regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5dbce9b2af50e93d4ec9d5171bff684daab83858"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b9f0fc018c3ad3a409e169294b928d60f2175102"
   },
   "source": [
    "Ridge regression is sensitive to the input features, therefore **standardization is usually recommended** before Ridge regression. <br/>\n",
    "Some useful info here: https://stats.stackexchange.com/questions/111017/question-about-standardizing-in-ridge-regression <br/>\n",
    "Here, standardization has already been carried out (see above), so we will go straight to training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a05d2b04b3e3339503010ec282232c83bb5e6de7"
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "ls = ['-','--',':']\n",
    "color = ['r','g','orange']\n",
    "\n",
    "for a in [0,2,2000]:\n",
    "    ridgeReg = Ridge(alpha=a)\n",
    "    ridgeReg.fit(xTrainPolyStan, yTrain)\n",
    "\n",
    "    # predict\n",
    "    xFit = np.linspace(0,1500,num=200).reshape(-1,1)\n",
    "    xFitPoly = Poly.transform(xFit)\n",
    "    xFitPolyStan = scaler.transform(xFitPoly)\n",
    "    yFit = ridgeReg.predict(xFitPolyStan)\n",
    "    \n",
    "    # plot\n",
    "    plt.plot(xFit,yFit, lw=3, color=color[i], zorder = 2, label= \"alpha = \" + str(a),linestyle=ls[i])\n",
    "    i = i + 1\n",
    "    \n",
    "plt.plot('GarageArea','SalePrice',data=dataTrain, marker = 'o', color = 'b', linestyle = '', zorder = 1)\n",
    "plt.ylabel('Sale Price (dollars)', fontsize = 18)\n",
    "plt.xlabel('Garage Area (square feet)', fontsize = 18)\n",
    "plt.legend(fontsize = 14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d100fd7ed5473aa8038617a0e41dd66120fd2096"
   },
   "source": [
    "In general, **the larger alpha is, the \"flatter\" the fit will be**. Eventually, as alpha approaches infinity, the prediction y_hat will just be a constant, since all thetas (except the intercept) will be regularized to zero.  \n",
    "In theory, **Ridge regression** with alpha = 0 should give the same result as regular linear regression, but sometimes that is not the case. See one post here: https://stackoverflow.com/questions/40570370/difference-between-linearregression-and-ridgealpha-0.  \n",
    "The post describes a polynomial model where Ridge regression overflowed, but linear regression did not. (we don't have this problem here.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6a006de8bcd7dfd8f8e03788d1eaf0be41746209"
   },
   "source": [
    "## Lasso Regression\n",
    "Least Absolute Shrinkage and Selection Operator Regression - LASSO  \n",
    "$Cost function: J(\\theta) = MSE(\\theta) + alpha (|\\theta_1| + |\\theta_2| + ... + |\\theta_n|)$\n",
    "\n",
    "The penalty is proportional to the **L1-norm** of theta. \n",
    "\n",
    "* The advantage of **Lasso** over **Ridge regression** lies in the **diamond shape** of contour of the **L1-norm** penalty, which leads to some of the thetas being eliminated (set to 0) quickly.  \n",
    "* This means the Lasso regression can perform automatic feature selection, when ridge regression cannot. \n",
    "* You can also understand the difference of Ridge and Lasso regression by understanding that, Ridge's L2-penalty heavily penalizes large thetas, but has nearly no penalization for small thetas (due to the square), whereas Lasso's l1-penalty gives appropriate penalization to even small thetas.  \n",
    "![](https://miro.medium.com/max/427/1*UiLesmZjRH6xY1V6UMFClw.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3f54c402040769cf02711a9e954b6c38a4a84332"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fb646cfe632cfd14a47d7ccd4bafbd08ff1b4bd1"
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "ls = ['-','--',':']\n",
    "color = ['r','g','orange']\n",
    "\n",
    "for a in [0.1,1,10]:\n",
    "    lassoReg = Lasso(alpha=a)\n",
    "    lassoReg.fit(xTrainPolyStan, yTrain)\n",
    "\n",
    "    # predict\n",
    "    xFit = np.linspace(0,1500,num=200).reshape(-1,1)\n",
    "    xFitPoly = Poly.transform(xFit)\n",
    "    xFitPolyStan = scaler.transform(xFitPoly)\n",
    "    yFit = lassoReg.predict(xFitPolyStan)\n",
    "    \n",
    "    # plot\n",
    "    plt.plot(xFit,yFit, lw=3, color=color[i], zorder = 2, label= \"alpha = \" + str(a),linestyle=ls[i])\n",
    "    i = i + 1\n",
    "    \n",
    "plt.plot('GarageArea','SalePrice',data=dataTrain, marker = 'o', color = 'b', linestyle = '', zorder = 1)\n",
    "plt.ylabel('Sale Price (dollars)', fontsize = 18)\n",
    "plt.xlabel('Garage Area (square feet)', fontsize = 18)\n",
    "plt.legend(fontsize = 14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "65005f621c76269143ad31488bf29c38a7020c95"
   },
   "source": [
    "As you can see, the three alpha tested gives very similar fits. As mentioned earlier, Lasso regression tends to return sparse theta vector, with many least important features eliminated (set to 0). Even when alpha is small, such elimination can happen, leading to similar fits for certain range of alphas.\n",
    "\n",
    "As mentioned in Scikit-Learn's [documentaion](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html), Lasso function is not advised to use with alpha = 0. In such cases, LinearRegression should be used instead. <br/>\n",
    "\n",
    "**Stochastic gradient descent** can be used for any type of optimization problem.  \n",
    "Here we show the example of **Lasso regression using SGDRegressor** from Scikit-Learn package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "22f8a4a238ebc590d9b07c0e8a21e2db6ae9a04c"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c6c7bc741cf4c340a0f0724b87608941053cf62c"
   },
   "outputs": [],
   "source": [
    "sgd = SGDRegressor(loss='squared_loss', penalty='l1', alpha=0.1)\n",
    "yTrain = yTrain.ravel() # format required by sgd\n",
    "sgd.fit(xTrainPolyStan, yTrain)\n",
    "\n",
    "# predict\n",
    "xFit = np.linspace(0,1500,num=200).reshape(-1,1)\n",
    "xFitPoly = Poly.transform(xFit)\n",
    "xFitPolyStan = scaler.transform(xFitPoly)\n",
    "yFit = sgd.predict(xFitPolyStan)\n",
    "\n",
    "plt.plot(xFit,yFit, lw=3, color='r', zorder = 2, label= \"alpha = 0.1\",linestyle='-')\n",
    "plt.plot('GarageArea','SalePrice',data=dataTrain, marker = 'o', color = 'b', linestyle = '', zorder = 1)\n",
    "plt.ylabel('Sale Price (dollars)', fontsize = 18)\n",
    "plt.xlabel('Garage Area (square feet)', fontsize = 18)\n",
    "plt.legend(fontsize = 14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6111829a4e06b6b5a1b311ab85247b64b0928d17"
   },
   "source": [
    "## Elastic Net\n",
    "Elastic net is somewhere between ridge regression and lasso regression. The cost function is: \n",
    "<br>\n",
    "$J(\\theta) = MSE(\\theta) + r\\cdot lasso\\_penalty + (1-r)\\cdot ridge\\_penalty. $\n",
    "</br>\n",
    "\n",
    "![](https://hackernoon.com/hn-images/1*gAmw-_z6v4bG9HcnPSAK3Q.png)\n",
    "![](https://cdn-images-1.medium.com/max/1200/0*kuuC8_3Q2YjoLoqt.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5f3724b844d70c568e63e8eecd7d9197d0ef7fa3"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5eae4d50f808324b627f290b1f5aa802cc2a929b"
   },
   "outputs": [],
   "source": [
    "yTrain = yTrain.reshape(-1,1)\n",
    "elasticReg = ElasticNet(alpha = 0.1, l1_ratio = 0.5)\n",
    "elasticReg.fit(xTrainPolyStan, yTrain)\n",
    "\n",
    "# predict\n",
    "xFit = np.linspace(0,1500,num=200).reshape(-1,1)\n",
    "xFitPoly = Poly.transform(xFit)\n",
    "xFitPolyStan = scaler.transform(xFitPoly)\n",
    "yFit = elasticReg.predict(xFitPolyStan)\n",
    "\n",
    "plt.plot(xFit,yFit, lw=3, color='r', zorder = 2, label= \"alpha = 0.1\",linestyle='-')\n",
    "plt.plot('GarageArea','SalePrice',data=dataTrain, marker = 'o', color = 'b', linestyle = '', zorder = 1)\n",
    "plt.ylabel('Sale Price (dollars)', fontsize = 18)\n",
    "plt.xlabel('Garage Area (square feet)', fontsize = 18)\n",
    "plt.legend(fontsize = 14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e7eb8e1f7dc8016fd609aa29393b5cb02774d371"
   },
   "source": [
    "**So, which model should we choose in practice?** <br/>\n",
    "Ridge regression: a good default. However, if sparse features are expected, ridge should be replaced by lasso or elastic net. <br/>\n",
    "Lasso regression: good for sparse feature selection. However, if the number of features is greater than the number of training samples, or when there are strongly correlated features, ridge or elastic net should be used. <br/>\n",
    "Elastic net: versatile since the ratio parameter r is tunable. A 50% ratio of l1 and l2-penalty can be a good default, too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7c72c04b728af563e7682f1546de1952ef547fb3"
   },
   "source": [
    "# Multi-variable models (for actual prediction)\n",
    "Here, we try to predict house prices with an elastic net model with fourth order features. <br/>\n",
    "Let's look at the training set again:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ff47007b8109fe40b1d0686cee9c1e94e67c0593"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "df46a5d4ab098fc63315aa81dcd2db3c2d015db9"
   },
   "outputs": [],
   "source": [
    "dataTrain = pd.read_csv('input/Lecture_04_3/train.csv')\n",
    "dataTrain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6e394ca6917542ab1f5e1123a287a3cab6e35051"
   },
   "source": [
    "Let's say we have reasons to believe the OverallQual, LotArea, TotalBsmtSF, 1stFlrSF, 2ndFlrSF,  GarageArea, and OpenPorchSF are some of the most relevant features for sale price prediction, and we want to build a four-degree (including interactions) linear model with elastic net regularization to predict sale price (**this is, of course, a huge simiplification of the actual problem, but here we just want to show how the regularized linear models work, and how well they can perform with limited information** ). Here is how we do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f908f0f188b657eac14c00f2682178949639959f"
   },
   "outputs": [],
   "source": [
    "# Obtain training data\n",
    "xTrain = dataTrain[['OverallQual','LotArea', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GarageArea', 'OpenPorchSF']].values\n",
    "yTrain = dataTrain['SalePrice'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "63426de224c09522fae4670f39be9fb102a9f1d5"
   },
   "source": [
    "## Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d5fed200c3fd2e49671866220d90d10cc95806d3"
   },
   "outputs": [],
   "source": [
    "# Transform the data\n",
    "poly2 = PolynomialFeatures(degree = 4, include_bias = False)\n",
    "xTrainPoly = poly2.fit_transform(xTrain)\n",
    "scaler = StandardScaler()\n",
    "xTrainPolyStan = scaler.fit_transform(xTrainPoly)\n",
    "\n",
    "# Fit the data\n",
    "elasticReg = ElasticNet(alpha = 0.1, l1_ratio = 0.85)\n",
    "elasticReg.fit(xTrainPolyStan, yTrain)\n",
    "\n",
    "# evaluate performance on training set\n",
    "yTrainHat = elasticReg.predict(xTrainPolyStan)\n",
    "\n",
    "# calculate rmse based on log(price)\n",
    "mse = mean_squared_error(np.log(yTrain), np.log(yTrainHat))\n",
    "rmse = np.sqrt(mse)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "10f21acc4900fe1fd9dd672fb8e6f37659278ad1"
   },
   "source": [
    " Let's plot predicted sale price and actual sale price:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9517dffdb40be8d5d8ede1cd877d4f4181c63c5b"
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0,800000,num=1000)\n",
    "plt.plot(yTrainHat, yTrain,marker='o', linestyle = '', zorder = 1, color='b')\n",
    "plt.plot(x, x, linestyle = '-',color='red',zorder=2,lw=3)\n",
    "plt.xlabel('predicted sale price (dollars)', fontsize = 18)\n",
    "plt.ylabel('actual sale price (dollars)', fontsize = 18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5914c36cf7c181a28066840f97cf768897b74354"
   },
   "source": [
    "Not bad. Let's try the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4adb677a59ba00065527fdea135ba0d733ae99ad"
   },
   "outputs": [],
   "source": [
    "dataTest = pd.read_csv('input/Lecture_04_3/test.csv')\n",
    "dataTest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e6c53b667aafc8522809c8bed34ecc4fe3851eb7"
   },
   "outputs": [],
   "source": [
    "dataTest = dataTest[['Id','OverallQual','LotArea', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GarageArea','OpenPorchSF']]\n",
    "dataTest.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "79655b20e64c4520b0cb5d2a34533921aa41c309"
   },
   "outputs": [],
   "source": [
    "# fill the nans with respective means.\n",
    "dictMs = {'TotalBsmtSF':dataTest['TotalBsmtSF'].mean(skipna=True),\n",
    "          'GarageArea':dataTest['GarageArea'].mean(skipna=True)}\n",
    "dataTest = dataTest.fillna(value=dictMs)\n",
    "dataTest.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ffbfbb988f3f268b7db1c02b6a749d9b954f7976"
   },
   "outputs": [],
   "source": [
    "xTest = dataTest[['OverallQual','LotArea', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GarageArea', 'OpenPorchSF']].values\n",
    "xTestPoly = poly2.transform(xTest)\n",
    "xTestPolyStan = scaler.transform(xTestPoly)\n",
    "yTestHat = elasticReg.predict(xTestPolyStan)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

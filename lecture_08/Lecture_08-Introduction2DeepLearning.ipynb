{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./image/deep_learning.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introduction to Deep Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/proxy/1*4wREvShuhT8kxxPFpKBd6A.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Brief Content of this Notebook:**\n",
    ">* Perceptron Learning Algorithm\n",
    "* Multi-Layer Perceptron and Backpropagation\n",
    "* Training an MLP with Tensorflow  \n",
    "* Fine-Tuning Neural Network Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **[Part 1: Perceptron Learning Algorithm](#Part-1:-Perceptron-Learning-Algorithm)**  \n",
    "\n",
    "\n",
    "* **[Part 2: Multi-Layer Perceptron and Backpropagation](#Part-2:-Multi-Layer-Perceptron-and-Backpropagation)**  \n",
    "\n",
    "\n",
    "* **[Part 3: Training an MLP with Tensorflow ](#Part-3:-Training-an-MLP-with-Tensorflow)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Perceptron Learning Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, the perceptron is an algorithm for supervised learning of binary classifiers. A binary classifier is a function which can decide whether or not an input, represented by a vector of numbers, belongs to some specific class. The Perceptron is one of the simplest artificial neural networks (ANNs) architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./image/perceptron_2.png\" width=\"1000\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets build the perceptron model with a simple classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/max/684/0*RuUpWDXIqL_tWpvH.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A perceptron consists of one or more inputs, a processor, and a single output. The inputs and output are numbers and each input connection is associated with a weight. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say, we have the input and output data\n",
    "* Input: \n",
    ">* x1 = Height of the person \n",
    ">* x2 = Weight of the person\n",
    "* Output:\n",
    ">* y = Gender(Male/Female)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/max/753/1*p2PTL_NRQA93-RDdnAGdvg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our motive is to fit a decision boundary(a line) that separates all the male samples from the female samples. We’ll use the perceptron model that’ll find the equation of the decision boundary for us. All we have to do is feed the input and output data for the model to train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/max/753/1*kjQhQv0R2Iw9bixtywW5rQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general equation of a straight line is $ax + by + c = 0$ or we can rephrase $w_0 + w_1x_1 + w_2x_2 = 0  \\quad \\quad (1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** \n",
    "1. If $P(x_P, y_P)$ lies on the line, $w_0 + w_1x_P + w_2x_P = 0$\n",
    "2. If $Q(x_Q, y_Q)$ lies above the line, $w_0 + w_1x_Q + w_2x_Q > 0$\n",
    "3. If $R(x_R, y_R)$ lies below the line, $w_0 + w_1x_R + w_2x_R < 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this intuition, we can classify any point by substituting its value in the line equation. If the resultant value is positive, the sample belongs to class Male $(Y = 1)$, if negative, the sample is a female sample $(Y = -1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/max/1001/1*3FFsnCSmKckphHshsRbH3Q.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On Plotting the above property discussed, we get a function called the Sign function. This is the activation function that we are going to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define equation $(1)$ as dot product of vectors $W$ and $X$ such as $X \\dot W = 0 \\quad (2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector $X$:\n",
    "![](https://miro.medium.com/max/429/1*Dusv9RkqITs34wAMNaEnvg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector $W$:\n",
    "![](https://miro.medium.com/max/305/1*w75nZrDOt_AwqkHWxBimUw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model correctly classifies the sample $X$ if $Y * (X \\dot W) > 0$. The sample is misclassified if $- Y * (X \\dot W) > 0$. We define a cost function for misclassified sample $X_i$:\n",
    "\n",
    "$$J(\\mathbf{W}; \\mathbf{X}_i; Y_i) = -Y_i\\mathbf{W}\\mathbf{X}_i$$\n",
    "\n",
    "We'll use an optimization algorithm, called the Gradient Descent to minimizes the cost function by gradually updating the weight values.\n",
    "\n",
    "Firstly, calculate the derivatives:\n",
    "\n",
    "$$\\nabla_{\\mathbf{W}}J(\\mathbf{W}; \\mathbf{X}_i; Y_i) = -Y_i\\mathbf{X}_i\n",
    "$$\n",
    "\n",
    "Update $W$:\n",
    "$$\\mathbf{W} = \\mathbf{W} + \\eta Y_i\\mathbf{X}_i\n",
    "$$\n",
    "with $\\eta$ is learning rate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/proxy/1*pPYFYOZ-8dja-kRrkmuGOQ.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3               4\n",
       "0    5.1  3.5  1.4  0.2     Iris-setosa\n",
       "1    4.9  3.0  1.4  0.2     Iris-setosa\n",
       "2    4.7  3.2  1.3  0.2     Iris-setosa\n",
       "3    4.6  3.1  1.5  0.2     Iris-setosa\n",
       "4    5.0  3.6  1.4  0.2     Iris-setosa\n",
       "..   ...  ...  ...  ...             ...\n",
       "145  6.7  3.0  5.2  2.3  Iris-virginica\n",
       "146  6.3  2.5  5.0  1.9  Iris-virginica\n",
       "147  6.5  3.0  5.2  2.0  Iris-virginica\n",
       "148  6.2  3.4  5.4  2.3  Iris-virginica\n",
       "149  5.9  3.0  5.1  1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', header=None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/anthony/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data = data[:100]\n",
    "data[4] = np.where(data.iloc[:, -1]=='Iris-setosa', 0, 1)\n",
    "data = np.asmatrix(data, dtype = 'float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(np.array(data[:50,0]), np.array(data[:50,2]), marker='o', label='setosa')\n",
    "plt.scatter(np.array(data[50:,0]), np.array(data[50:,2]), marker='o', label='versicolor')\n",
    "plt.xlabel('petal length')\n",
    "plt.ylabel('sepal length')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:        \n",
    "    def fit(self, features, labels, num_iter=10):\n",
    "        self.weights = np.zeros(shape=(1, features.shape[1] + 1))\n",
    "        self.misclassified_ = []\n",
    "        \n",
    "        for epoch in range(num_iter):\n",
    "            misclassified = False\n",
    "            for x, label in zip(features, labels):\n",
    "                x = np.insert(x, 0, 1)\n",
    "                y = np.dot(self.weights, x.transpose())\n",
    "                \n",
    "                target = 1.0 if (y > 0) else 0.0\n",
    "                \n",
    "                delta = label[0] - target\n",
    "                \n",
    "                if delta != 0:\n",
    "                    misclassified += 1\n",
    "                    self.weights += delta * x\n",
    "            \n",
    "            print('Epoch {}'.format(epoch))\n",
    "            \n",
    "            self.misclassified_.append(misclassified)\n",
    "        \n",
    "    def predict(self, features):\n",
    "        new_features = np.concatenate([np.ones((len(features), 1)), features], axis=1)\n",
    "        y_pred = new_features * self.weights.T\n",
    "        print(y_pred)\n",
    "        y_pred = np.asarray(y_pred.flatten())[0]\n",
    "        print(y_pred)\n",
    "        labels_pred = np.where(y_pred > 0, 1, 0)\n",
    "        return labels_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "features = data[:, :-1]\n",
    "labels = data[:, -1]\n",
    "\n",
    "num_iter = 10\n",
    "\n",
    "model = Perceptron()\n",
    "model.fit(features, labels, num_iter)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = np.arange(1, num_iter+1)\n",
    "plt.plot(epochs, model.misclassified_)\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('misclassified')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-11.49]\n",
      " [ -9.47]\n",
      " [-10.49]\n",
      " [ -8.98]\n",
      " [-11.74]\n",
      " [-11.26]\n",
      " [-10.36]\n",
      " [-10.5 ]\n",
      " [ -8.56]\n",
      " [ -9.53]\n",
      " [-12.02]\n",
      " [ -9.76]\n",
      " [ -9.58]\n",
      " [-10.59]\n",
      " [-15.1 ]\n",
      " [-14.43]\n",
      " [-13.34]\n",
      " [-11.27]\n",
      " [-11.45]\n",
      " [-11.83]\n",
      " [ -9.9 ]\n",
      " [-11.25]\n",
      " [-13.38]\n",
      " [ -8.55]\n",
      " [ -8.2 ]\n",
      " [ -8.54]\n",
      " [ -9.54]\n",
      " [-11.08]\n",
      " [-11.24]\n",
      " [ -8.93]\n",
      " [ -8.68]\n",
      " [-10.5 ]\n",
      " [-13.46]\n",
      " [-14.45]\n",
      " [ -9.53]\n",
      " [-11.34]\n",
      " [-12.45]\n",
      " [ -9.53]\n",
      " [ -9.44]\n",
      " [-10.61]\n",
      " [-11.68]\n",
      " [ -6.81]\n",
      " [-10.16]\n",
      " [ -9.46]\n",
      " [ -9.53]\n",
      " [ -9.14]\n",
      " [-11.53]\n",
      " [ -9.86]\n",
      " [-11.91]\n",
      " [-10.66]\n",
      " [  7.3 ]\n",
      " [  7.14]\n",
      " [  9.03]\n",
      " [  8.33]\n",
      " [  8.99]\n",
      " [  8.91]\n",
      " [  8.15]\n",
      " [  4.33]\n",
      " [  8.08]\n",
      " [  6.92]\n",
      " [  6.7 ]\n",
      " [  6.85]\n",
      " [  7.48]\n",
      " [  9.37]\n",
      " [  3.98]\n",
      " [  6.43]\n",
      " [  8.74]\n",
      " [  6.42]\n",
      " [ 10.96]\n",
      " [  6.54]\n",
      " [  9.91]\n",
      " [  5.87]\n",
      " [ 11.85]\n",
      " [  9.29]\n",
      " [  6.74]\n",
      " [  6.9 ]\n",
      " [  9.48]\n",
      " [ 10.57]\n",
      " [  8.66]\n",
      " [  3.77]\n",
      " [  6.49]\n",
      " [  5.75]\n",
      " [  5.82]\n",
      " [ 12.72]\n",
      " [  8.96]\n",
      " [  7.08]\n",
      " [  8.21]\n",
      " [  9.53]\n",
      " [  6.22]\n",
      " [  7.61]\n",
      " [  9.11]\n",
      " [  8.49]\n",
      " [  6.7 ]\n",
      " [  4.58]\n",
      " [  7.82]\n",
      " [  6.41]\n",
      " [  6.99]\n",
      " [  6.96]\n",
      " [  2.41]\n",
      " [  6.83]]\n",
      "[-11.49  -9.47 -10.49  -8.98 -11.74 -11.26 -10.36 -10.5   -8.56  -9.53\n",
      " -12.02  -9.76  -9.58 -10.59 -15.1  -14.43 -13.34 -11.27 -11.45 -11.83\n",
      "  -9.9  -11.25 -13.38  -8.55  -8.2   -8.54  -9.54 -11.08 -11.24  -8.93\n",
      "  -8.68 -10.5  -13.46 -14.45  -9.53 -11.34 -12.45  -9.53  -9.44 -10.61\n",
      " -11.68  -6.81 -10.16  -9.46  -9.53  -9.14 -11.53  -9.86 -11.91 -10.66\n",
      "   7.3    7.14   9.03   8.33   8.99   8.91   8.15   4.33   8.08   6.92\n",
      "   6.7    6.85   7.48   9.37   3.98   6.43   8.74   6.42  10.96   6.54\n",
      "   9.91   5.87  11.85   9.29   6.74   6.9    9.48  10.57   8.66   3.77\n",
      "   6.49   5.75   5.82  12.72   8.96   7.08   8.21   9.53   6.22   7.61\n",
      "   9.11   8.49   6.7    4.58   7.82   6.41   6.99   6.96   2.41   6.83]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(features)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Multi-Layer Perceptron and Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The perceptron is very useful for classifying data sets that are linearly separable. They encounter serious limitations with data sets that do not conform to this pattern. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://images.deepai.org/glossary-terms/multilayer-perceptron-1878889.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MultiLayer Perceptron (MLPs) breaks this restriction and classifies datasets which are not linearly separable.  They do this by using a more robust and complex architecture to learn regression and classification models for difficult datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/proxy/1*eloYEyFrblGHVZhU345PJw.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-layer Perceptron (MLP) is a supervised learning algorithm that learns a function $f(\\cdot): R^m \\rightarrow R^o$ by training on a dataset, where $m$ is the number of dimensions for input and $o$ is the number of dimensions for output. Given a set of features $X = {x_1, x_2, ..., x_m}$ and a target $y$, it can learn a non-linear function approximator for either classification or regression. It is different from logistic regression, in that between the input and the output layer, there can be one or more non-linear layers, called hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://scikit-learn.org/stable/_images/multilayerperceptron_network.png\" width=\"300\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input or Visible Layers**\n",
    "\n",
    "This layer accepts input features. It provides information from the outside world to the network, no computation is performed at this layer, nodes here just pass on the information(features) to the hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hidden Layers**\n",
    "\n",
    "Nodes of this layer are not exposed to the outer world, they are the part of the abstraction provided by any neural network. Hidden layer performs all sort of computation on the features entered through the input layer and transfer the result to the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output Layer**\n",
    "\n",
    "The final hidden layer is called the output layer and it is responsible for outputting a value or vector of values that correspond to the format required for the problem. The choice of activation function in he output layer is strongly constrained by the type of problem that you are modeling. For example: \n",
    ">* A regression problem may have a single output neuron and the neuron may have no activation function.\n",
    ">* A binary classification problem may have a single output neuron and use a sigmoid activation function to output a value between 0 and 1 to represent the probability of predicting a value for the class 1. This can be turned into a crisp class value by using a threshold of 0.5 and snap values less than the threshold to 0 otherwise to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are basically three steps in the training of the model.\n",
    "1. Forward pass\n",
    "2. Calculate error or loss\n",
    "3. Backward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Forward pass**\n",
    "\n",
    "In this step of training the model, we just pass the input to model and multiply with weights and add bias at every layer and find the calculated output of the model.\n",
    "![](https://miro.medium.com/max/1225/1*9dByklf9ybdvVtHq6RrOgw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Loss Calculate**\n",
    "\n",
    "When we pass the data instance(or one example) we will get some output from the model that is called Predicted output(pred_out) and we have the label with the data that is real output or expected output(Expect_out). Based upon these both we calculate the loss that we have to backpropagate(using Backpropagation algorithm). There is various Loss Function that we use based on our output and requirement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Backward Pass**\n",
    "\n",
    "After calculating the loss, we backpropagate the loss and updates the weights of the model by using gradient. This is the main step in the training of the model. In this step, weights will adjust according to the gradient flow in that direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/max/770/1*vGj29ZBD1kH1kDlGQspPxA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of Y can be anything ranging from -inf to +inf. The neuron really doesn’t know the bounds of the value. We decided to add “activation functions” for this purpose. To check the Y value produced by a neuron and decide whether outside connections should consider this neuron as “fired” or not. Or rather let’s say — “activated” or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/max/1225/1*p_hyqAtyI8pbt2kEl6siOQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Backpropagation](https://www.youtube.com/watch?v=Ilg3gGewQ5U&t=44s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Training an MLP with Tensorflow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/smoreira/MultiLayerPerceptron/raw/master/imagem_mlp.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import and parse the dataset.\n",
    "2. Select the type of model.\n",
    "3. Train the model.\n",
    "4. Evaluate the model's effectiveness.\n",
    "5. Use the trained model to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure imports\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import and parse the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width  labels\n",
       "0             6.4          2.8           5.6          2.2       2\n",
       "1             5.0          2.3           3.3          1.0       1\n",
       "2             4.9          2.5           4.5          1.7       2\n",
       "3             4.9          3.1           1.5          0.1       0\n",
       "4             5.7          3.8           1.7          0.3       0\n",
       "..            ...          ...           ...          ...     ...\n",
       "115           5.5          2.6           4.4          1.2       1\n",
       "116           5.7          3.0           4.2          1.2       1\n",
       "117           4.4          2.9           1.4          0.2       0\n",
       "118           4.8          3.0           1.4          0.1       0\n",
       "119           5.5          2.4           3.7          1.0       1\n",
       "\n",
       "[120 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data from url\n",
    "raw_data = pd.read_csv('https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv')\n",
    "columns_name = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'labels']\n",
    "raw_data.columns = columns_name\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each label is associated with string name (for example, \"setosa\"), but machine learning typically relies on numeric values. The label numbers are mapped to a named representation, such as:\n",
    "\n",
    ">* **0**: Iris setosa\n",
    ">* **1**: Iris versicolor\n",
    ">* **2**: Iris virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.4, 2.8, 5.6, 2.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.7, 3.8, 1.7, 0.3]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = raw_data.iloc[:, :-1].values\n",
    "features[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels for model\n",
    "labels = np.zeros((len(features), 3), dtype=np.int8)\n",
    "for i in raw_data['labels'].index:\n",
    "    labels[i][raw_data['labels'][i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, raw_data['labels'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Select the type of model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.tensorflow.org/images/custom_estimators/full_network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(4,))\n",
    "dense = layers.Dense(10, activation=\"relu\")\n",
    "x = dense(inputs)\n",
    "x = layers.Dense(10, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(3)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"mnist_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 193\n",
      "Trainable params: 193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.0460 - accuracy: 0.2188\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.8366 - accuracy: 0.2500\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7636 - accuracy: 0.3854\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7326 - accuracy: 0.5521\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7012 - accuracy: 0.5312\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6774 - accuracy: 0.5521\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6590 - accuracy: 0.5208\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6431 - accuracy: 0.5625\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6305 - accuracy: 0.5625\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6174 - accuracy: 0.5729\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6065 - accuracy: 0.5833\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5979 - accuracy: 0.6146\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5892 - accuracy: 0.6458\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5834 - accuracy: 0.6354\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5737 - accuracy: 0.6979\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5653 - accuracy: 0.7396\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5576 - accuracy: 0.7188\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5517 - accuracy: 0.7188\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.5452 - accuracy: 0.7292\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.7812\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5329 - accuracy: 0.7500\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5276 - accuracy: 0.7604\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5243 - accuracy: 0.7396\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5186 - accuracy: 0.8021\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5140 - accuracy: 0.8229\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7812\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5052 - accuracy: 0.7917\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 0.8229\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.8125\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4916 - accuracy: 0.8438\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.8438\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4840 - accuracy: 0.8229\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4833 - accuracy: 0.8646\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4796 - accuracy: 0.8646\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4733 - accuracy: 0.8229\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4758 - accuracy: 0.8333\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4660 - accuracy: 0.8333\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.8646\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.8750\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.8958\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.8958\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4525 - accuracy: 0.8021\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.9271\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.9375\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.8958\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.8958\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4363 - accuracy: 0.8958\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4328 - accuracy: 0.9167\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.9688\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.8646\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4246 - accuracy: 0.9062\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.9062\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.9167\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4171 - accuracy: 0.9271\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4145 - accuracy: 0.9688\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4120 - accuracy: 0.9167\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.9479\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4081 - accuracy: 0.9583\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4054 - accuracy: 0.9583\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4031 - accuracy: 0.9375\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4033 - accuracy: 0.9271\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.9479\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3976 - accuracy: 0.9479\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3966 - accuracy: 0.9583\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3929 - accuracy: 0.9062\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3891 - accuracy: 0.9688\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3915 - accuracy: 0.9167\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3851 - accuracy: 0.9688\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3833 - accuracy: 0.9479\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3816 - accuracy: 0.9583\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3786 - accuracy: 0.9688\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3776 - accuracy: 0.9688\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3753 - accuracy: 0.9688\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3732 - accuracy: 0.9583\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.9688\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3690 - accuracy: 0.9479\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.9688\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3668 - accuracy: 0.9688\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3624 - accuracy: 0.9688\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3617 - accuracy: 0.9688\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3607 - accuracy: 0.9688\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3564 - accuracy: 0.9375\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3563 - accuracy: 0.9583\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3536 - accuracy: 0.9688\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3652 - accuracy: 0.9271\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3540 - accuracy: 0.9583\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3469 - accuracy: 0.9479\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3443 - accuracy: 0.9688\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3422 - accuracy: 0.9688\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.3400 - accuracy: 0.9688\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3420 - accuracy: 0.9479\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3369 - accuracy: 0.9688\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3438 - accuracy: 0.9375\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3378 - accuracy: 0.9479\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3359 - accuracy: 0.9479\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3297 - accuracy: 0.9688\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3275 - accuracy: 0.9688\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3265 - accuracy: 0.9583\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3340 - accuracy: 0.9271\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3294 - accuracy: 0.9688\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3261 - accuracy: 0.9271\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3202 - accuracy: 0.9688\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3160 - accuracy: 0.9688\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3141 - accuracy: 0.9688\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3164 - accuracy: 0.9688\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3106 - accuracy: 0.9688\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3093 - accuracy: 0.9688\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3157 - accuracy: 0.9375\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.9479\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3059 - accuracy: 0.9688\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3040 - accuracy: 0.9688\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3027 - accuracy: 0.9688\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3026 - accuracy: 0.9688\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2976 - accuracy: 0.9688\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2967 - accuracy: 0.9688\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2961 - accuracy: 0.9688\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2921 - accuracy: 0.9688\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2928 - accuracy: 0.9688\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2887 - accuracy: 0.9688\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2873 - accuracy: 0.9688\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2901 - accuracy: 0.9688\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2835 - accuracy: 0.9688\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2823 - accuracy: 0.9688\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2808 - accuracy: 0.9688\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2868 - accuracy: 0.9583\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2777 - accuracy: 0.9688\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2752 - accuracy: 0.9688\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2752 - accuracy: 0.9688\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2765 - accuracy: 0.9688\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2728 - accuracy: 0.9688\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2704 - accuracy: 0.9688\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2771 - accuracy: 0.9375\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2701 - accuracy: 0.9479\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2668 - accuracy: 0.9688\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2638 - accuracy: 0.9688\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2632 - accuracy: 0.9688\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2601 - accuracy: 0.9688\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2597 - accuracy: 0.9688\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2692 - accuracy: 0.9583\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2599 - accuracy: 0.9688\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2555 - accuracy: 0.9688\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2531 - accuracy: 0.9688\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2507 - accuracy: 0.9688\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2577 - accuracy: 0.9688\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2543 - accuracy: 0.9688\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2507 - accuracy: 0.9583\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2452 - accuracy: 0.9688\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2445 - accuracy: 0.9688\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2491 - accuracy: 0.9583\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2427 - accuracy: 0.9583\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.9688\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.9688\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2404 - accuracy: 0.9583\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2356 - accuracy: 0.9688\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2541 - accuracy: 0.9375\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2361 - accuracy: 0.9688\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2343 - accuracy: 0.9688\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2348 - accuracy: 0.9688\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2372 - accuracy: 0.9583\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2297 - accuracy: 0.9688\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2267 - accuracy: 0.9688\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2249 - accuracy: 0.9688\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2251 - accuracy: 0.9688\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2239 - accuracy: 0.9688\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2213 - accuracy: 0.9688\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2206 - accuracy: 0.9688\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2212 - accuracy: 0.9688\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.2137 - accuracy: 0.93 - 0s 2ms/step - loss: 0.2230 - accuracy: 0.9583\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2191 - accuracy: 0.9688\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2263 - accuracy: 0.9583\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2174 - accuracy: 0.9688\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2155 - accuracy: 0.9688\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2146 - accuracy: 0.9688\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2127 - accuracy: 0.9688\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2124 - accuracy: 0.9583\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2089 - accuracy: 0.9688\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2079 - accuracy: 0.9688\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2062 - accuracy: 0.9688\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2076 - accuracy: 0.9688\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2047 - accuracy: 0.9688\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2121 - accuracy: 0.9375\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2046 - accuracy: 0.9688\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2008 - accuracy: 0.9688\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2002 - accuracy: 0.9688\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2007 - accuracy: 0.9688\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1983 - accuracy: 0.9688\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1996 - accuracy: 0.9688\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1983 - accuracy: 0.9688\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2051 - accuracy: 0.9688\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1956 - accuracy: 0.9688\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1938 - accuracy: 0.9688\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1965 - accuracy: 0.9688\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1911 - accuracy: 0.9688\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1908 - accuracy: 0.9688\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1965 - accuracy: 0.9479\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1901 - accuracy: 0.9688\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1958 - accuracy: 0.9688\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1910 - accuracy: 0.9479\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1910 - accuracy: 0.9688\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1865 - accuracy: 0.9688\n",
      "1/1 - 0s - loss: 0.1735 - accuracy: 1.0000\n",
      "Test loss: 0.17351453006267548\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.01),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=32, epochs=200)\n",
    "\n",
    "test_scores = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"Test loss:\", test_scores[0])\n",
    "print(\"Test accuracy:\", test_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>30</th>\n",
       "      <th>4</th>\n",
       "      <th>setosa</th>\n",
       "      <th>versicolor</th>\n",
       "      <th>virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     30    4  setosa  versicolor  virginica\n",
       "0   5.9  3.0     4.2         1.5          1\n",
       "1   6.9  3.1     5.4         2.1          2\n",
       "2   5.1  3.3     1.7         0.5          0\n",
       "3   6.0  3.4     4.5         1.6          1\n",
       "4   5.5  2.5     4.0         1.3          1\n",
       "5   6.2  2.9     4.3         1.3          1\n",
       "6   5.5  4.2     1.4         0.2          0\n",
       "7   6.3  2.8     5.1         1.5          2\n",
       "8   5.6  3.0     4.1         1.3          1\n",
       "9   6.7  2.5     5.8         1.8          2\n",
       "10  7.1  3.0     5.9         2.1          2\n",
       "11  4.3  3.0     1.1         0.1          0\n",
       "12  5.6  2.8     4.9         2.0          2\n",
       "13  5.5  2.3     4.0         1.3          1\n",
       "14  6.0  2.2     4.0         1.0          1\n",
       "15  5.1  3.5     1.4         0.2          0\n",
       "16  5.7  2.6     3.5         1.0          1\n",
       "17  4.8  3.4     1.9         0.2          0\n",
       "18  5.1  3.4     1.5         0.2          0\n",
       "19  5.7  2.5     5.0         2.0          2\n",
       "20  5.4  3.4     1.7         0.2          0\n",
       "21  5.6  3.0     4.5         1.5          1\n",
       "22  6.3  2.9     5.6         1.8          2\n",
       "23  6.3  2.5     4.9         1.5          1\n",
       "24  5.8  2.7     3.9         1.2          1\n",
       "25  6.1  3.0     4.6         1.4          1\n",
       "26  5.2  4.1     1.5         0.1          0\n",
       "27  6.7  3.1     4.7         1.5          1\n",
       "28  6.7  3.3     5.7         2.5          2\n",
       "29  6.4  2.9     4.3         1.3          1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = test_data.iloc[:, :-1].values\n",
    "labels_test = test_data.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1940 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1939624845981598, 1.0]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(data_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/anthony/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      2.0\n",
       "1      1.0\n",
       "2      NaN\n",
       "3      0.0\n",
       "4      0.0\n",
       "      ... \n",
       "115    1.0\n",
       "116    1.0\n",
       "117    0.0\n",
       "118    0.0\n",
       "119    1.0\n",
       "Name: labels, Length: 120, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['labels'][2] = None\n",
    "raw_data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['labels'].fillna(raw_data['labels'].mean(), inplace=True)\n",
    "raw_data['labels'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-42-47d3adafe9e9>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-42-47d3adafe9e9>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    if ? != ?:\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for column in data.columns:\n",
    "    if ? != ?:\n",
    "        data[column].?(?, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
